---
layout: post
title: "Building a grocery planner - prototype"
date: 2024-01-28 20:10:36 -0800
categories: devlog homelab
---

I wanted to build a grocery planner as a toy app for my homelab. The idea is to get a web app where I
can look up for recipe names or ingredients and get the list of groceries to buy. On the way,
I wanted to learn about how to setup and coordinate servers through kubernetes and try out [Bun](https://bun.sh/),
[Grats](https://github.com/captbaritone/grats) and [Relay](https://github.com/facebook/relay) for web development.

I'll go over my initial reactions about using these for the first time in a project. This is also a log on I iterated
over the design of the app. Will divide it into a series of blog posts to keep it consumable:

- **Prototype**: **[This post!]** Building the minimum end to end app to validate my approach and setup the enviroment. Why did
  I choose specific libraries and what I had to build to make them work together. The App works but is slow, 10 secs per request.
- **Job Queues**: Decoupling scraping from search. Setup job queues to build a daily table of recipes I'm interested on so I can
  build local recipe search. Log what can I do to support more recipes. Recipe scraping works but search doesn't feel good.
- **Recipe Search**: Prototype recipe search using an inverse index, evaluate string matching heuristics. Recipe search works
  and feels okay but is not integrated to the app.
- **Typeaheads**: Upgrading the search prototype to a working web app. It works okayish and is fast! < 500ms per request. Thoughts
  on what can I do to get to 100ms.

I'll try to approximate how much load this system might be able to handle. You can see the final code [here](https://github.com/qsiandre/meal-plan).

### Proof of concept

Started by working on a proof of concept. Get a simple form where you can add a url from traders joes,
and get the ingredients, picture and title of the recipe. Traders joe's website is not server side rendered, so I need to wait
for all the app to load. I want to see if I could run this in my home lab.

I get design paralysis, so tried to get some inspiration form [vercel's v0](https://v0.dev/). The tool works gret and got an
initial mock UI that I could implement. Setting up the front end, was a good first milestone to get some early wins going.

For the web app, I wanted to use Bun as the web server. Bun is a fast all batteries included runtime for JS. I haven't setup
Relay by myself, so wanted to learn about how to build a template to run in projects I want to build with Bun.
Relay requires a GraphQL server schema, usually I manually wire it by writing the an schema.graphql and doing the bindings in node,
this time I wanted to use Grats to replicates the code first approach I'm used to at Meta.

### Client Setup

In the client, the first challenge was to setup Relay. Relay depends in a code transform to extract the GraphQL fragments. Fragments then
generate the typescript files that will comply with the GraphQL Schema, and be used by the Relay runtime. Bun is relatively new and there isn’t recommended transform to do this wiring. The idea is to replace the post processor graphql string template literals with references to the relay module generated by the relay compiler. So created a small bundling script and plugin that can do this transform by adapting the
existing ESBuild transform. More details [here](https://github.com/qsiandre/meal-plan/blob/main/plugins/relayPlugin.ts).

```typescript
export const relay: BunPlugin = {
  name: "extract relay",
  setup(build) {
    build.onLoad({ filter: /\.(tsx|ts)$/, namespace: "file" }, ({ path }) => {
      const file = readFileSync(path, "utf8");
      const contents = compile(path, file, {
        artifactDirectory: "__generated__",
      });
      // this was the trickiest part, didn't now that you could pass the content
      // to the tsx loader...
      return { contents, loader: "tsx" };
    });
  },
};
```

In the server, I run Bun as web server, there is an example of Grats using yoga that runned out of the box after connecting it to a Bun request handler.
Creating a chrome instance that is managed by puppeteer was really smooth, I had some Bun scripts running for quick prototyping. I find using Bun pretty
easy, most commands are similar to what you node has, and some common usecases are built in, like reading environment variables.

The form uses React state to go through the steps, when all URLs are ready there is a single GraphQL mutation that
kicks off the scraping in the server. Relay then helps with the loading states and type generation, finally when the
mutation finishes, it returns a list of recipes that are stored in React state and passed around components.

I decided to go with this approach because:

1. Starting Chrome and navigating to the URL, loading JS and scraping the HTML in single request will take 10+ secs. So `useLazyLoadQuery`
   wasn't as ergonomic, as I would need to change the params and rely on Suspense for this. `useMutation` in the other hand exposes both the
   request and a bool that you can use to imperatively show a loading indicator.
2. Reading directly from Relay without React state seemed like an overkill, most of the interactions in the stepper don't require server
   data so the benefits of colocation don't apply.
3. The biggest unknown was on search, and setting up jobs for scraping. If I need to colocate more server reads I can just refactor and Relay
   makes it really easy to iterate on.

After having the prototype code complete I was able to run it locally; it was slow, but usable. Now the final
feasibility test; make it run in my homelab that runs on 3 raspberry pi’s which are way more constraint than my m2 mini.
To make it run there I created a docker container that bundles alpine, chrome and my bun server.
Setted kubernetes and created a private docker repository in my homelab.

The kubernetes config was a bit esoteric but after a bunch of copy pasting I got it running. The main ramp up was on terminology, after
trying and failing multiple times got used to it. So `Ingress > Service > Pod`.

- Pods are where you can run containers, you can see their logs whe they are deployed using `kubectl logs <pod-id>`, also `kubectl describe pod <pod-id>`
  will hint about errors.
- Services are the middle layer, used to expose pods to the kubernetes cluster. This can be debugged by port forwarding `kubectl port-forward <service-id> <to>:<from>`, if this fails
  to access your pod, there is something wrong with the pod. This will get important while setting up search.
- Ingress describe the externally accessible URLs, and will redirect the traffic to services. You test them just typing the URL in the browser. If it fails it's a DNS issue.
  For my small toy app, was an overkill but I can see how this can get usefull as you deploy something more complicated and want to add more pods to support your traffic. Wish this was
  in a single step for quick iteration.

<pre class="mermaid">
  graph LR
  Browser --> Relay --> Grats --> Chrome
</pre>

The hot path is scraping, it consumes 300MB of memory per request, takes 10 - 20 seconds to finish. Since I have 3 machines with 4GB of memory, it could create aprox 10 with
400MB request limit pods. I can run 4 queries each minute assuming each query takes 15 seconds. So QPS is `4 / 60 * 10 = 0.66 QPS`. To go beyond this need to move Chrome out
of the web request through jobs that scrape recipes and store them in a DB. since I'm mostly interested in Recipes from Trader's Joes and those don't change frequently this is an okay tradeoff.

### Homelab Setup

- [Homelab](https://rpi4cluster.com): I have 3 raspberry pi's connected to the local network and with kubernetes running, but all can fit in 1
- [Docker](https://rpi4cluster.com): Setup a local docker repository for kubernetes to access.
- [MariaDB](https://pimylifeup.com/raspberry-pi-mysql/): MySQL database to hold data beyond requests.
- [Jupyter and Conda](https://medium.com/@nrk25693/how-to-add-your-conda-environment-to-your-jupyter-notebook-in-just-4-steps-abeab8b8d084): Fast prototyping environment to have ready in your development environment.

<script type="module">
  import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10/dist/mermaid.esm.min.mjs';
  mermaid.initialize({ startOnLoad: true });
</script>
